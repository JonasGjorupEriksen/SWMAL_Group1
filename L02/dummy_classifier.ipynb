{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Implementing a dummy binary-classifier with fit-predict interface\n",
    "\n",
    "We begin with the MNIST data-set and will reuse the data loader from Scikit-learn. Next we create a dummy classifier, and compare the results of the SGD and dummy classifiers using the MNIST data...\n",
    "\n",
    "#### Qa  Load and display the MNIST data\n",
    "\n",
    "There is a `sklearn.datasets.fetch_openml` dataloader interface in Scikit-learn. You can load MNIST data like \n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784',??) # needs to return X, y, replace '??' with suitable parameters! \n",
    "# Convert to [0;1] via scaling (not always needed)\n",
    "#X = X / 255.\n",
    "```\n",
    "\n",
    "but you need to set parameters like `return_X_y` and `cache` if the default values are not suitable! \n",
    "\n",
    "Check out the documentation for the `fetch_openml` MNIST loader, try it out by loading a (X,y) MNIST data set, and plot a single digit via the `MNIST_PlotDigit` function here (input data is a 28x28 NMIST subimage)\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "```\n",
    "\n",
    "Finally, put the MNIST loader into a single function called `MNIST_GetDataSet()` so you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Function to plot an MNIST digit\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to load MNIST dataset\n",
    "def MNIST_GetDataSet():\n",
    "    # Load data from https://www.openml.org/d/554\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, cache=True)\n",
    "    X = X / 255.0  # Scale pixel values to [0, 1]\n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "# Plot a single digit. The first one in the dataset\n",
    "MNIST_PlotDigit(X[2])\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb  Add a Stochastic Gradient Decent [SGD] Classifier\n",
    "\n",
    "Create a train-test data-set for MNIST and then add the `SGDClassifier` as done in [HOML], p.103.\n",
    "\n",
    "Split your data and run the fit-predict for the classifier using the MNIST data.(We will be looking at cross-validation instead of the simple fit-predict in a later exercise.)\n",
    "\n",
    "Notice that you have to reshape the MNIST X-data to be able to use the classifier. It may be a 3D array, consisting of 70000 (28 x 28) images, or just a 2D array consisting of 70000 elements of size 784.\n",
    "\n",
    "A simple `reshape()` could fix this on-the-fly:\n",
    "```python\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "```\n",
    "\n",
    "Remember to use the category-5 y inputs\n",
    "\n",
    "```python\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "```\n",
    "instead of the `y`'s you are getting out of the dataloader. In effect, we have now created a binary-classifier, that enable us to classify a particular data sample, $\\mathbf{x}(i)$ (that is a 28x28 image), as being a-class-5 or not-a-class-5. \n",
    "\n",
    "Test your model on using the test data, and try to plot numbers that have been categorized correctly. Then also find and plots some misclassified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "X.shape=(70000, 784)\n",
      "the ones where we have quessed true\n",
      "y_pred: False y_test 7\n",
      "True Negative0\n",
      "y_pred: False y_test 2\n",
      "True Negative1\n",
      "y_pred: False y_test 1\n",
      "True Negative2\n",
      "y_pred: False y_test 0\n",
      "True Negative3\n",
      "y_pred: False y_test 4\n",
      "True Negative4\n",
      "y_pred: False y_test 1\n",
      "True Negative5\n",
      "y_pred: False y_test 4\n",
      "True Negative6\n",
      "y_pred: False y_test 9\n",
      "True Negative7\n",
      "y_pred: False y_test 9\n",
      "True Negative9\n",
      "y_pred: True y_test 5\n",
      "True Positive15\n",
      "y_pred: True y_test 5\n",
      "True Positive23\n",
      "y_pred: True y_test 5\n",
      "True Positive45\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# load the data\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "# reshape if needed\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "\n",
    "# split data set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# What are we looking fore\n",
    "y_train_5 = (y_train == '5') # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == '5')\n",
    "\n",
    "# Train\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Test\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "# Score\n",
    "#identify the correct answers\n",
    "print(\"the ones where we have quessed true\")\n",
    "for i in range(10):\n",
    "    if y_pred[i] == False and y_test_5[i] == False:\n",
    "        print(f\"y_pred: {y_pred[i]} y_test {y_test[i]}\")\n",
    "        print(f\"True Negative{i}\")\n",
    "\n",
    "for i in range(50):\n",
    "    if y_pred[i] == True and y_test_5[i] == True:\n",
    "        print(f\"y_pred: {y_pred[i]} y_test {y_test[i]}\")\n",
    "        print(f\"True Positive{i}\")\n",
    "\n",
    "MNIST_PlotDigit(X_test[7])\n",
    "MNIST_PlotDigit(X_test[15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: False y_test 5\n",
      "false negative 8\n",
      "y_pred: False y_test 5\n",
      "false negative 153\n",
      "y_pred: False y_test 5\n",
      "false negative 211\n",
      "y_pred: True y_test 3\n",
      " false positive245\n",
      "y_pred: False y_test 5\n",
      "false negative 340\n",
      "y_pred: False y_test 5\n",
      "false negative 352\n",
      "y_pred: False y_test 5\n",
      "false negative 406\n",
      "y_pred: False y_test 5\n",
      "false negative 460\n",
      "y_pred: False y_test 5\n",
      "false negative 469\n",
      "y_pred: False y_test 5\n",
      "false negative 478\n",
      "y_pred: False y_test 5\n",
      "false negative 502\n",
      "y_pred: True y_test 3\n",
      " false positive569\n",
      "y_pred: False y_test 5\n",
      "false negative 645\n",
      "y_pred: False y_test 5\n",
      "false negative 674\n",
      "y_pred: False y_test 5\n",
      "false negative 720\n",
      "y_pred: False y_test 5\n",
      "false negative 751\n",
      "y_pred: False y_test 5\n",
      "false negative 791\n",
      "y_pred: False y_test 5\n",
      "false negative 857\n",
      "y_pred: True y_test 3\n",
      " false positive938\n",
      "y_pred: False y_test 5\n",
      "false negative 955\n",
      "y_pred: False y_test 5\n",
      "false negative 970\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9068   40]\n",
      " [ 191  701]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# identify the falses\n",
    "for i in range(1000):\n",
    "    if y_pred[i] == False and y_test_5[i] == True:\n",
    "        print(f\"y_pred: {y_pred[i]} y_test {y_test[i]}\")\n",
    "        print(f\"false negative {i}\")\n",
    "    \n",
    "    if y_pred[i] == True and y_test_5[i] == False:\n",
    "        print(f\"y_pred: {y_pred[i]} y_test {y_test[i]}\")\n",
    "        print(f\" false positive{i}\")\n",
    "\n",
    "# plotting some the digits it guessed wrong\n",
    "MNIST_PlotDigit(X_test[8])\n",
    "\n",
    "MNIST_PlotDigit(X_test[245])\n",
    "\n",
    "# cross val score from the handbook\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "cm = confusion_matrix(y_test_5, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Implement a dummy binary classifier\n",
    "\n",
    "Now we will try to create a Scikit-learn compatible estimator implemented via a python class. Follow the code found on p.107 3rd [HOML] (for [HOML] 1. and 2. editions: name you estimator `DummyClassifier` instead of `Never5Classifyer`).\n",
    "\n",
    "Here our Python class knowledge comes into play. The estimator class hierarchy looks like\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L02/Figs/class_base_estimator.png\" alt=\"WARNING: could not get image from server.\" style=\"width:500px\">\n",
    "\n",
    "All Scikit-learn classifiers inherit from `BaseEstimator` (and possibly also `ClassifierMixin`), and they must have a `fit-predict` function pair (strangely not in the base class!) and you can actually find the `sklearn.base.BaseEstimator` and `sklearn.base.ClassifierMixin` python source code somewhere in you anaconda install dir, if you should have the nerves to go to such interesting details.\n",
    "\n",
    "But surprisingly you may just want to implement a class that contains the `fit-predict` functions, ___without inheriting___ from the `BaseEstimator`, things still work due to the pythonic 'duck-typing': you just need to have the class implement the needed interfaces, obviously `fit()` and `predict()` but also the more obscure `get_params()` etc....then the class 'looks like' a `BaseEstimator`...and if it looks like an estimator, it _is_ an estimator (aka. duck typing).\n",
    "\n",
    "Templates in C++ also allow the language to use compile-time duck typing!\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Duck_typing\n",
    "\n",
    "Call the fit-predict on a newly instantiated `DummyClassifier` object, and find a way to extract the accuracy `score` from the test data. You may implement an accuracy function yourself or just use the `sklearn.metrics.accuracy_score` function. \n",
    "\n",
    "Finally, compare the accuracy score from your `DummyClassifier` with the scores found in [HOML] \"Measuring Accuracy Using Cross-Validation\", p.107. Are they comparable? \n",
    "\n",
    "(Notice that Scikit-learn now also have a `sklearn.dummy.DummyClassifier`, but you are naturally supposed to create you own...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "X.shape=(70000, 784)\n",
      "True Positive = 0\n",
      "True negative = 9108\n",
      "False Positive = 0\n",
      "False negative = 892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "\n",
    "class DummyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert X.ndim == 2\n",
    "        return np.zeros(X.shape[0],dtype=bool)\n",
    "    \n",
    "\n",
    "# load the data\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "# reshape if needed\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "\n",
    "# split data set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# What are we looking fore\n",
    "y_train_5 = (y_train == '5') # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == '5')\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "# Train\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Test\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# Score\n",
    "#identify the correct answers\n",
    "True_Positive = 0\n",
    "True_Negative = 0\n",
    "False_Positive = 0\n",
    "False_Negative = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    if y_pred[i] == False and y_test_5[i] == False:\n",
    "        True_Negative += 1\n",
    "    if y_pred[i] == True and y_test_5[i] == True:\n",
    "        True_Positive += 1\n",
    "    if y_pred[i] == False and y_test_5[i] == True:\n",
    "        False_Negative += 1\n",
    "    if y_pred[i] == True and y_test_5[i] == False:\n",
    "        False_Positive += 1\n",
    "\n",
    "print(f\"True Positive = {True_Positive}\")\n",
    "print(f\"True negative = {True_Negative}\")\n",
    "      \n",
    "print(f\"False Positive = {False_Positive}\")\n",
    "print(f\"False negative = {False_Negative}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qd concluding remarks in text.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2018-12-19| CEF, initial.\n",
    "2018-02-06| CEF, updated and spell checked.\n",
    "2018-02-08| CEF, minor text update.\n",
    "2018-03-05| CEF, updated with SHN comments.\n",
    "2019-09-02| CEF, updated for ITMAL v2.\n",
    "2019-09-04| CEF, updated and added conclusion Q.\n",
    "2020-01-25| CEF, F20 ITMAL update.\n",
    "2020-02-04| CEF, updated page numbers to HOMLv2.\n",
    "2020-09-03| CEF, E20 ITMAL update, udpated figs paths.\n",
    "2020-09-06| CEF, added alt text.\n",
    "2020-09-18| CEF, added binary-classifier text to Qb to emphasise 5/non-5 classification.\n",
    "2021-01-12| CEF, F21 ITMAL update, moved revision tabel.\n",
    "2021-08-02| CEF, update to E21 ITMAL.\n",
    "2022-01-25| CEF, update to F22 SWMAL.\n",
    "2023-02-07| CEF, update HOML page numbers.\n",
    "2024-02-14| CEF, added note on sklearn.dummy.DummyClassifier.\n",
    "2024-09-13| CEF, updated p.107 and editions text references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.517px",
    "left": "1230px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
